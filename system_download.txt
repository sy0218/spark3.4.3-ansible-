[server_ip]|192.168.56.10|192.168.56.11|192.168.56.12

[zookeeper_ip]|192.168.56.10|192.168.56.11|192.168.56.12
-----------------------[zoo.cfg-start]-----------------------
[tickTime=]|2000
[initLimit=]|11
[syncLimit=]|5
[dataDir=]|/data/sy0218/apache-zookeeper-3.7.2-bin/data
[clientPort=]|2181
-----------------------[zoo.cfg-end]-----------------------


[postgresql_data_directory]|/pgdb/pg_data
-----------------------[postgresql.conf-start]-----------------------
[data_directory]|'/pgdb/pg_data'
[listen_addresses]|'*'
[port]|5432
-----------------------[postgresql.conf-end]-----------------------


[hadoop_ip]|192.168.56.10|192.168.56.11|192.168.56.12
[need_dir]|/hadoop/hdfs_work|/hadoop/hdfs|/hadoop/data1|/hadoop/data2|/hadoop/jn|/hadoop/data
-----------------------[core-site.xml-start]-----------------------
[fs.default.name]|hdfs://192.168.56.10:9000
[fs.defaultFS]|hdfs://my-hadoop-cluster
[hadoop.tmp.dir]|file:///hadoop/hdfs_work/hadoop-root
[ha.zookeeper.quorum]|192.168.56.10:2181,192.168.56.11:2181,192.168.56.12:2181
-----------------------[core-site.xml-end]-----------------------

-----------------------[hdfs-site.xml-start]-----------------------
[dfs.namenode.name.dir]|file:///hadoop/hdfs/nn
[dfs.datanode.data.dir]|file:///hadoop/data1,file:///hadoop/data2
[dfs.journalnode.edits.dir]|/hadoop/jn
[dfs.namenode.rpc-address.my-hadoop-cluster.namenode1]|192.168.56.10:8020
[dfs.namenode.rpc-address.my-hadoop-cluster.namenode2]|192.168.56.11:8020
[dfs.namenode.http-address.my-hadoop-cluster.namenode1]|192.168.56.10:50070
[dfs.namenode.http-address.my-hadoop-cluster.namenode2]|192.168.56.11:50070
[dfs.namenode.shared.edits.dir]|qjournal://192.168.56.10:8485;192.168.56.11:8485;192.168.56.12:8485/my-hadoop-cluster
[dfs.name.dir]|/hadoop/data/name
[dfs.data.dir]|/hadoop/data/data
-----------------------[hdfs-site.xml-end]-----------------------

-----------------------[mapred-site.xml-start]-----------------------
[mapreduce.framework.name]|yarn
-----------------------[mapred-site.xml-end]-----------------------

-----------------------[yarn-site.xml-start]-----------------------
[yarn.resourcemanager.hostname.rm1]|192.168.56.10
[yarn.resourcemanager.hostname.rm2]|192.168.56.11
[yarn.resourcemanager.webapp.address.rm1]|192.168.56.10:8088
[yarn.resourcemanager.webapp.address.rm2]|192.168.56.11:8088
[yarn.resourcemanager.zk-address]|192.168.56.10:2181,192.168.56.11:2181,192.168.56.12:2181
[yarn.nodemanager.resource.memory-mb]|8192
-----------------------[yarn-site.xml-end]-----------------------

-----------------------[hadoop-env.sh-start]-----------------------
[export JAVA_HOME=]|/usr/lib/jvm/java-8-openjdk-amd64
[export HADOOP_HOME=]|/data/sy0218/hadoop-3.3.5
-----------------------[hadoop-env.sh-end]-----------------------

-----------------------[workers-start]-----------------------
192.168.56.10
192.168.56.11
192.168.56.12
-----------------------[workers-end]-----------------------


[hive_ip]|192.168.56.10
-----------------------[hive-site.xml-start]-----------------------
[javax.jdo.option.ConnectionURL]|jdbc:postgresql://192.168.56.10:5432/sy0218
[hive.metastore.db.type]|postgres
[javax.jdo.option.ConnectionDriverName]|org.postgresql.Driver
[javax.jdo.option.ConnectionUserName]|hive
[javax.jdo.option.ConnectionPassword]|hive0218
[hive.metastore.warehouse.dir]|/user/hive/warehouse
[hive.execution.engine]|mr
-----------------------[hive-site.xml-end]-----------------------


[spark_ip]|192.168.56.10|192.168.56.11|192.168.56.12
-----------------------[spark-env.sh-start]-----------------------
[export SPARK_HOME=]|/data/sy0218/spark
[export SPARK_CONF_DIR=]|/data/sy0218/spark/conf
[export JAVA_HOME=]|/usr/lib/jvm/java-8-openjdk-amd64
[export HADOOP_HOME=]|/data/sy0218/hadoop-3.3.5
[export HADOOP_CONF_DIR=]|/data/sy0218/hadoop-3.3.5/etc/hadoop
[export SPARK_MASTER_WEBUI_PORT=]|18080
-----------------------[spark-env.sh-end]-----------------------

-----------------------[spark-defaults.conf-start]-----------------------
[spark.master]|yarn
[spark.eventLog.enabled]|true
[spark.eventLog.dir]|/data/sy0218/spark/logs
[spark.yarn.am.memory]|200m
[spark.yarn.am.cores]|1
-----------------------[spark-defaults.conf-end]-----------------------

-----------------------[spark-workers-start]-----------------------
192.168.56.10
192.168.56.11
192.168.56.12
-----------------------[spark-workers-end]-----------------------
